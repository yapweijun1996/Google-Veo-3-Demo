TITLE: Python Code Style Example
DESCRIPTION: Illustrates specific Python coding conventions for variable assignment and function parameter formatting, as recommended by Google's style guides.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Template.ipynb#_snippet_3

LANGUAGE: python
CODE:
```
var = value
function(
  parameter=value
)
```

----------------------------------------

TITLE: Generate Content with Uploaded Files (Python)
DESCRIPTION: Demonstrates how to make `GenerateContent` requests that reference an uploaded file. You can pass the file object directly in the Python SDK. This example creates a prompt that starts with text and includes an image.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#_snippet_4

LANGUAGE: Python
CODE:
```
MODEL_ID = "gemini-2.5-flash" # @param ["gemini-2.5-flash-lite-preview-06-17","gemini-2.0-flash","gemini-2.5-flash","gemini-2.5-pro"] {"allow-input":true, isTemplate: true}

response = client.models.generate_content(
    model=MODEL_ID,
    contents=["Describe the image with a creative description.", sample_file]
)

print(response.text)
```

----------------------------------------

TITLE: Example: Basic Gemini Live API Text Prompt
DESCRIPTION: Demonstrates a simple invocation of the `run` function to send a basic text prompt to the Gemini Live API and receive a text response. This is a starting point for interacting with the API.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#_snippet_10

LANGUAGE: python
CODE:
```
await run(prompt="Hello?", tools=None, modality = "TEXT")
```

----------------------------------------

TITLE: Display First Dataset Example
DESCRIPTION: Prints the content of the first example document from the loaded 20 Newsgroups training dataset, starting from the 'Lines' marker.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/clustering_with_embeddings.ipynb#_snippet_6

LANGUAGE: python
CODE:
```
# @title Display First Dataset Example
idx = newsgroups_train.data[0].index('Lines')
print(newsgroups_train.data[0][idx:])
```

----------------------------------------

TITLE: Python Setup for Gemini API Key
DESCRIPTION: Sets up the Google API key from Colab secrets into an environment variable for use in subsequent API calls. This is a prerequisite for running the examples.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/System_instructions_REST.ipynb#_snippet_0

LANGUAGE: python
CODE:
```
import os
from google.colab import userdata
```

LANGUAGE: python
CODE:
```
os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')
```

----------------------------------------

TITLE: Gemini API Migration Guide
DESCRIPTION: Information regarding the migration to Gemini 2 and the new Google GenAI SDK. Details the differences between the new and older SDKs and provides a link to the comprehensive migration guide.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/README.md#_snippet_1

LANGUAGE: APIDOC
CODE:
```
Gemini API Migration to Gemini 2:

New SDK: `google-genai` (v1.0)
- Fully compatible with all Gemini API models and features.
- Supports new features like live API (audio/video streaming), improved tool usage (code execution, function calling), and media generation (Imagen, Veo).
- Connects via Google AI Studio or Vertex AI.

Existing SDK: `google-generativeai`
- Continues to support original Gemini models.
- Can be used with Gemini 2 models but with a limited feature set.
- All new features will be developed in the new Google GenAI SDK.

Migration Guide: https://ai.google.dev/gemini-api/docs/migrate
```

----------------------------------------

TITLE: Example: Gemini Live API Function Call
DESCRIPTION: Shows how to use the Gemini Live API with function calls. It defines a prompt to turn lights on and provides tool definitions including the 'turn_on_the_lights' and 'turn_off_the_lights' functions.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#_snippet_12

LANGUAGE: python
CODE:
```
prompt = "Turn on the lights"

tools = [
    {'function_declarations': [turn_on_the_lights, turn_off_the_lights]}
]

await run(prompt, tools=tools, modality = "TEXT")
```

----------------------------------------

TITLE: Initialize Gemini Client
DESCRIPTION: Initializes the Google Generative AI client using your API key, preparing it for making API calls.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#_snippet_2

LANGUAGE: python
CODE:
```
from google import genai

client = genai.Client(api_key=GEMINI_API_KEY)
```

----------------------------------------

TITLE: Install Gemini SDK
DESCRIPTION: Installs the Google Generative AI Python SDK from PyPI, ensuring you have the latest version for API access.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#_snippet_0

LANGUAGE: python
CODE:
```
%pip install -q -U "google-genai>=1.0.0"
```

----------------------------------------

TITLE: Set Up Gemini API Client
DESCRIPTION: Initializes the Gemini API client by retrieving the API key from Colab Secrets and creating a client instance. This step is crucial for authentication.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Opossum_search.ipynb#_snippet_1

LANGUAGE: python
CODE:
```
from google import genai
from google.genai.types import GenerateContentConfig
from google.colab import userdata

GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')
client = genai.Client(api_key=GOOGLE_API_KEY)
```

----------------------------------------

TITLE: Gemini API Chat Example
DESCRIPTION: Demonstrates a multi-turn conversation with the Gemini API using a `curl` command. It shows how to structure the JSON payload for user and model messages to simulate a chat flow. The output is filtered to show relevant text.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Prompting_REST.ipynb#_snippet_6

LANGUAGE: bash
CODE:
```
%%bash
curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY" \
    -H 'Content-Type: application/json' \
    -X POST \
    -d '{
      "contents": [
        {"role":"user",
         "parts":[{
           "text": "In one sentence, explain how a computer works to a young child."}]},
        {"role": "model",
         "parts":[{
           "text": "A computer is like a smart helper that can store information, do math problems, and follow our instructions to make things happen."}]},
        {"role": "user",
         "parts":[{
           "text": "Okay, how about a more detailed explanation to a high schooler?"}]},
      ]
    }' 2> /dev/null | grep -C 5 "text"
```

----------------------------------------

TITLE: Extract URLs with Gemini API
DESCRIPTION: This Python code snippet demonstrates how to extract URLs from a given text using the Google Gemini API. It defines a prompt to identify URLs and then uses the `client.models.generate_content` method to process the text. The output is formatted as markdown.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#_snippet_7

LANGUAGE: python
CODE:
```
url_text = """
  Gemini API billing FAQs

  This page provides answers to frequently asked questions about billing
  for the Gemini API. For pricing information, see the pricing page
  https://ai.google.dev/pricing.
  For legal terms, see the terms of service
  https://ai.google.dev/gemini-api/terms#paid-services.

  What am I billed for?
  Gemini API pricing is based on total token count, with different prices
  for input tokens and output tokens. For pricing information,
  see the pricing page https://ai.google.dev/pricing.

  Where can I view my quota?
  You can view your quota and system limits in the Google Cloud console
  https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/quotas.

  Is GetTokens billed?
  Requests to the GetTokens API are not billed,
  and they don't count against inference quota.
"""

url_prompt = f"""
  From the given text, extract the following entities and return a list of them.
  Entities to extract: URLs.
  Text: {url_text}
  Do not duplicate entities.
  Return your answer in a markdown format:
"

response = client.models.generate_content(
    model=MODEL_ID,
    contents=url_prompt
)

Markdown(response.text)
```

----------------------------------------

TITLE: Python Output Formatting Examples
DESCRIPTION: Demonstrates common Python functions for displaying output, including plain text, formatted Markdown, JSON, and images, as used in notebooks.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/CONTRIBUTING.md#_snippet_11

LANGUAGE: python
CODE:
```
print("This is a plain text output.")
```

LANGUAGE: python
CODE:
```
from IPython.display import display, Markdown
display(Markdown("# This is Markdown output"))
```

LANGUAGE: python
CODE:
```
import json
json_string = {"key": "value"}
print(json.dumps(json_string, indent=4))
```

LANGUAGE: python
CODE:
```
from IPython.display import display, Image
display(Image(url='http://example.com/image.png'))
```

----------------------------------------

TITLE: Example: Gemini Live API Code Execution
DESCRIPTION: Demonstrates the code execution tool with the Gemini Live API. It prompts the model to compute a complex mathematical problem, enabling the model to write and run Python code to find the solution.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#_snippet_13

LANGUAGE: python
CODE:
```
prompt="Can you compute the largest prime palindrome under 100000."

tools = [
    {'code_execution': {}}
]

await run(prompt, tools=tools, modality="TEXT")
```

----------------------------------------

TITLE: Install Google Generative AI Library
DESCRIPTION: Installs the necessary Google Generative AI client library for Python. This is a prerequisite for using the Gemini API.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#_snippet_0

LANGUAGE: python
CODE:
```
%pip install -U -q "google-genai>=1.0.0"
```

----------------------------------------

TITLE: Initialize Gemini Client and Select Model
DESCRIPTION: Initializes the Gemini API client using the provided API key and selects the desired Gemini model for use. The example uses 'gemini-2.5-flash', but other models like 'gemini-2.5-pro' are also available.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#_snippet_2

LANGUAGE: python
CODE:
```
from google import genai
from google.genai import types

client = genai.Client(api_key=GOOGLE_API_KEY)

MODEL_ID = "gemini-2.5-flash" # @param ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash", "gemini-2.5-flash-lite-preview-06-17"] {"allow-input":true, isTemplate: true}
```

----------------------------------------

TITLE: Setup Gemini API Key
DESCRIPTION: Retrieves your Gemini API key from Colab Secrets, which is necessary for authenticating and initializing the client.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#_snippet_1

LANGUAGE: python
CODE:
```
from google.colab import userdata

GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')
```

----------------------------------------

TITLE: Gemini API: Generate Content (REST)
DESCRIPTION: Demonstrates how to call the Gemini API's `generateContent` method using `curl` for both text-only and multimodal (image + text) prompts. It includes details on constructing the JSON payload, setting headers, and handling API keys.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Prompting_REST.ipynb#_snippet_5

LANGUAGE: APIDOC
CODE:
```
Endpoint: POST https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={API_KEY}

Description:
  Generates content based on a given prompt, which can include text and/or image data.

Parameters:
  - model (path parameter): The name of the Gemini model to use (e.g., gemini-2.0-flash).
  - key (query parameter): Your Google API key.
  - Content-Type (header): Must be 'application/json'.
  - Request Body (JSON):
    {
      "contents": [
        {
          "parts": [
            // Text part
            {"text": "Your text prompt here"},
            // Optional: Image part
            {
              "inline_data": {
                "mime_type": "image/jpeg",
                "data": "BASE64_ENCODED_IMAGE_DATA"
              }
            }
          ]
        }
      ]
    }

Examples:

1. Text-only prompt:
   ```bash
   curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY" \
       -H 'Content-Type: application/json' \
       -X POST \
       -d '{ "contents": [{ "parts":[{ "text": "Give me python code to sort a list." } }] }' 2> /dev/null
   ```

2. Multimodal prompt (image + text):
   First, prepare the request JSON with base64 encoded image data:
   ```bash
   # For Colab (GNU base64):
   echo '{ "contents":[ { "parts":[ {"text": "Describe this image."}, { "inline_data": { "mime_type":"image/jpeg", "data": "'$(base64 -w0 image.jpg)'" } } ] } ] }' > request.json
   
   # For Mac (BSD base64):
   # echo '{ "contents":[ { "parts":[ {"text": "Describe this image."}, { "inline_data": { "mime_type":"image/jpeg", "data": "'$(base64 -i image.jpg)'" } } ] } ] }' > request.json
   ```
   Then, send the request:
   ```bash
   curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GOOGLE_API_KEY}" \
           -H 'Content-Type: application/json' \
           -d @request.json
   ```

   Alternatively, for Mac users, a direct curl command with inline base64 encoding:
   ```bash
   curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GOOGLE_API_KEY}" \
           -H 'Content-Type: application/json' \
           -d '{ "contents":[ { "parts":[ {"text": "foo"}, { "inline_data": { "mime_type":"image/jpeg", "data": "'$(base64 -i image.jpg)'" } } ] } ] }'   2> /dev/null  | grep -C 5 "text"
   ```

Notes:
  - Ensure your API key is correctly set in the environment variable or URL.
  - The `base64` encoding method might differ between operating systems (GNU vs. BSD).
  - The `2> /dev/null` redirects stderr to null, suppressing potential curl error messages for cleaner output.
  - The `grep -C 5 "text"` in the Mac example is for demonstration to filter output and is not part of the core API call.

```

----------------------------------------

TITLE: Gemini API SDKs Overview
DESCRIPTION: Lists the official SDKs available for interacting with the Gemini API across multiple programming languages. These SDKs simplify API calls and provide language-specific abstractions.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/README.md#_snippet_0

LANGUAGE: APIDOC
CODE:
```
Gemini API SDKs:

- Python: https://github.com/googleapis/python-genai
- Go: https://github.com/google/generative-ai-go
- Node.js: https://github.com/google/generative-ai-js
- Dart (Flutter): https://github.com/google/generative-ai-dart
- Android: https://github.com/google/generative-ai-android
- Swift: https://github.com/google/generative-ai-swift

These SDKs facilitate integration with the Gemini API, supporting various features including multimodal capabilities, tool usage, and streaming.
```

----------------------------------------

TITLE: Upload and Use Markdown File (Python)
DESCRIPTION: This example shows how to embed text files, such as Markdown, into prompts using the File API. It involves downloading a Markdown file, uploading it with a specified display name and MIME type, and then using it in a content generation request.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#_snippet_6

LANGUAGE: Python
CODE:
```
# Download a markdown file and ask a question.
from google.genai import types
from IPython.display import Markdown

!curl -so contrib.md https://raw.githubusercontent.com/google-gemini/cookbook/main/CONTRIBUTING.md

md_file = client.files.upload(
    file="contrib.md",
    config={
        "display_name": "CONTRIBUTING.md",
        "mime_type": "text/markdown"
    }
)

response = client.models.generate_content(
    model=MODEL_ID,
    contents=[
        "What should I do before I start writing, when following these guidelines?",
        md_file,
    ]
)

display(Markdown(response.text))
```

----------------------------------------

TITLE: Python Setup for Gemini File API
DESCRIPTION: Instructions to prepare a Python virtual environment, set the API key, install dependencies, and run the sample code.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/file-api/README.md#_snippet_0

LANGUAGE: bash
CODE:
```
# Prepare a virtual environment for Python.
python3 -m venv venv
source venv/bin/activate

# Add API key to .env file
touch .env
echo "GOOGLE_API_KEY='YOUR_API_KEY'" >> .env

# Install dependencies.
pip3 install -U -r requirements.txt

# Run the sample code.
python3 sample.py
```

----------------------------------------

TITLE: Embeddings API Reference
DESCRIPTION: Reference for the `embed_content` method used to generate text embeddings. This method takes a model name, content, and optional configuration to produce numerical vector representations of the input text.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#_snippet_9

LANGUAGE: APIDOC
CODE:
```
client.models.embed_content(model: str, contents: Union[str, List[str], GenerateContentRequest], config: Optional[EmbedContentConfig] = None) -> EmbedContentResponse

  Generates embeddings for the given content using the specified model.

  Parameters:
    model: The name of the embedding model to use (e.g., 'embedding-001').
    contents: The text content to embed. Can be a single string, a list of strings, or a GenerateContentRequest object.
    config: Optional configuration for embedding, such as output dimensionality.
      - output_dimensionality: The desired dimensionality of the embeddings (e.g., 10, 128, 768).

  Returns:
    An EmbedContentResponse object containing the embeddings.
    Each embedding is a list of float values.

  Example:
    import google.generativeai as genai
    from google.generativeai import types

    genai.configure(api_key='YOUR_API_KEY')
    model_id = 'embedding-001'
    text_to_embed = "This is a sample sentence."

    response = genai.models.embed_content(model=model_id, contents=text_to_embed)
    embedding = response.embeddings[0].values
    print(f"Embedding dimension: {len(embedding)}")
```

----------------------------------------

TITLE: Node.js Setup for Gemini File API
DESCRIPTION: Instructions to set the API key, install Node.js dependencies, and run the sample application.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/file-api/README.md#_snippet_1

LANGUAGE: bash
CODE:
```
# Make sure npm is installed first. 

# Add API key to .env file
touch .env
echo "GOOGLE_API_KEY='YOUR_API_KEY'" >> .env

# Install dependencies.
npm install

# Run the sample code.
npm start
```

----------------------------------------

TITLE: Batch Embed Content
DESCRIPTION: Generates embeddings for multiple text inputs in a single API call, which is more efficient for processing lists of text.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#_snippet_6

LANGUAGE: python
CODE:
```
result = client.models.embed_content(
    model=MODEL_ID,
    contents=[
      'What is the meaning of life?',
      'How much wood would a woodchuck chuck?',
      'How does the brain work?'])

for embedding in result.embeddings:
    # Print just a part of the embedding to keep the output manageable
  print(str(embedding)[:50], '... TRIMMED]')
```

----------------------------------------

TITLE: Use Google Search Grounding
DESCRIPTION: Demonstrates how to use Google Search grounding with the Gemini API. By including a 'google_search' tool in the generation configuration, the model can access real-time information to answer queries, such as the latest sports match results.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#_snippet_3

LANGUAGE: python
CODE:
```
from IPython.display import HTML, Markdown

response = client.models.generate_content(
    model=MODEL_ID,
    contents='What was the latest Indian Premier League match and who won?',
    config={"tools": [{"google_search": {}}]}
)

# print the response
display(Markdown(f"Response:\n {response.text}"))
# print the search details
print(f"Search Query: {response.candidates[0].grounding_metadata.web_search_queries}")
# urls used for grounding
print(f"Search Pages: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}")

display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))
```

----------------------------------------

TITLE: Configure Google Gemini API Key and Client
DESCRIPTION: Demonstrates how to retrieve a Google API key from Colab Secrets and initialize the Google Generative AI client. This is a prerequisite for interacting with Gemini models.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Template.ipynb#_snippet_1

LANGUAGE: python
CODE:
```
from google.colab import userdata
from google import genai

GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
client = genai.Client(api_key=GOOGLE_API_KEY)
```

----------------------------------------

TITLE: Set up API Key
DESCRIPTION: Retrieves the Google API key from Colab Secrets, which is required to authenticate and initialize the Gemini client. Ensure your API key is stored in a Colab Secret named 'GOOGLE_API_KEY'.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#_snippet_1

LANGUAGE: python
CODE:
```
from google.colab import userdata

GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
```

----------------------------------------

TITLE: Configure Gemini API Key and Client
DESCRIPTION: Sets up the Google Generative AI client by retrieving an API key from Colab Secrets and initializing the client. Requires the 'GOOGLE_API_KEY' secret to be set.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#_snippet_1

LANGUAGE: python
CODE:
```
from google import genai
from google.colab import userdata

GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')
client = genai.Client(api_key=GOOGLE_API_KEY)
```

----------------------------------------

TITLE: Initialize Gemini Client and Model
DESCRIPTION: Sets up the Gemini API client using an API key and defines the model to be used for inference. It supports retrieving API keys from Colab's userdata or direct assignment.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#_snippet_1

LANGUAGE: python
CODE:
```
from google import genai
from google.colab import userdata
api_key = userdata.get("GOOGLE_API_KEY") # If you are not using Colab you can set the API key directly

# Create a client
client = genai.Client(api_key=api_key)

# Define the model you are going to use
model_id =  "gemini-2.5-flash" # or "gemini-2.5-flash-lite-preview-06-17"  , "gemini-2.5-flash","gemini-2.5-pro"
```

----------------------------------------

TITLE: Ground Gemini with URL Context
DESCRIPTION: Demonstrates using the `UrlContext` tool to process content directly from a web page URL. This enables Gemini models to access and analyze live web information, anchoring responses to specific online content.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#_snippet_7

LANGUAGE: python
CODE:
```
prompt = """
based on https://ai.google.dev/gemini-api/docs/models, what are the key
differences between Gemini 1.5, Gemini 2.0 and Gemini 2.5 models?
Create a markdown table comparing the differences.
"""

tools = []
tools.append(types.Tool(url_context=types.UrlContext))

config = types.GenerateContentConfig(
    tools=tools,
)

response = client.models.generate_content(
      contents=[prompt],
      model=MODEL_ID,
      config=config
)

display(Markdown(response.text))
```

----------------------------------------

TITLE: Define Text for Extraction
DESCRIPTION: Provides the input text from which entities will be extracted. This example text describes travel options from an airport.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#_snippet_3

LANGUAGE: python
CODE:
```
directions = """
  To reach the Colosseum from Rome's Fiumicino Airport (FCO),
  your options are diverse. Take the Leonardo Express train from FCO
  to Termini Station, then hop on metro line A towards Battistini and
  alight at Colosseo station.
  Alternatively, hop on a direct bus, like the Terravision shuttle, from
  FCO to Termini, then walk a short distance to the Colosseum on
  Via dei Fori Imperiali.
  If you prefer a taxi, simply hail one at the airport and ask to be taken
  to the Colosseum. The taxi will likely take you through Via del Corso and
  Via dei Fori Imperiali.
  A private transfer service offers a direct ride from FCO to the Colosseum,
  bypassing the hustle of public transport.
  If you're feeling adventurous, consider taking the train from
  FCO to Ostiense station, then walking through the charming
  Trastevere neighborhood, crossing Ponte Palatino to reach the Colosseum,
  passing by the Tiber River and Via della Lungara.
  Remember to validate your tickets on the metro and buses,
  and be mindful of pickpockets, especially in crowded areas.
  No matter which route you choose, you're sure to be awed by the
  grandeur of the Colosseum.
"""
```

----------------------------------------

TITLE: Summarize YouTube Video with Gemini
DESCRIPTION: Demonstrates how to use a YouTube URL as a `file_data` part in a prompt to have Gemini models summarize the video content. This leverages multimodal understanding for video analysis.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#_snippet_5

LANGUAGE: python
CODE:
```
yt_link = "https://www.youtube.com/watch?v=XV1kOFo1C8M"

response = client.models.generate_content(
    model=MODEL_ID,
    contents= types.Content(
        parts=[
            types.Part(text="Summarize this video."),
            types.Part(
                file_data=types.FileData(file_uri=yt_link)
            )
        ]
    )
)

Markdown(response.text)
```

----------------------------------------

TITLE: Gemini: Multi-Tool Orchestration
DESCRIPTION: Illustrates how to use multiple tools within a single request, overcoming the previous limitation of one tool per prompt. This example combines code execution, Google search, and custom function calls.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#_snippet_16

LANGUAGE: python
CODE:
```
prompt = """
  Hey, I need you to do three things for me.

  1. Then compute the largest prime plaindrome under 100000.
  2. Then use google search to lookup unformation about the largest earthquake in california the week of Dec 5 2024?
  3. Turn on the lights

  Thanks!
  """

tools = [
    {'google_search': {}},
    {'code_execution': {}},
    {'function_declarations': [turn_on_the_lights, turn_off_the_lights]}
]

await run(prompt, tools=tools, modality="TEXT")
```

----------------------------------------

TITLE: Role Prompting: German Tour Guide Example
DESCRIPTION: Illustrates role prompting by configuring the model to act as a German tour guide. It then asks for recommendations on art museums in Berlin and Cologne.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#_snippet_4

LANGUAGE: python
CODE:
```
system_prompt = """
    You are a German tour guide. Your task is to give recommendations to people visiting your country.
"""

prompt = 'Could you give me some recommendations on art museums in Berlin and Cologne?'

response = client.models.generate_content(
    model=MODEL_ID,
    config=types.GenerateContentConfig(system_instruction=system_prompt),
    contents=prompt
)

print(response.text)
```

----------------------------------------

TITLE: Gemini API Function Calling Overview
DESCRIPTION: Explains the concept of function calling with Gemini API, detailing how function declarations, OpenAPI schemas, and the `tools` object are used to enable generative AI applications to interact with external functions. The model returns a JSON object with function names and arguments based on these declarations.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb#_snippet_1

LANGUAGE: APIDOC
CODE:
```
Function Calling with Gemini API:

Purpose:
  Enables generative AI applications to use functions as tools by passing function descriptions to the language model. The model responds with a function name and arguments to call.

Key Components:
  - Function Declarations: Descriptions of functions, including name, parameters (in OpenAPI schema format), and an optional description. These are passed in a `tools` object.
  - OpenAPI Schema: Used to define function parameters. A subset is supported, specified using JSON when using curl.
  - Model Response: A JSON object containing the name of a function to call and its arguments, based on the provided declarations.
  - Developer Action: The developer uses the model's response to execute the actual function call.

Supported Models:
  All Gemini models support function calling.

Usage with cURL:
  Function and parameter information is included in the `tools` element of the request payload, using OpenAPI schema format for parameter definitions.
```

----------------------------------------

TITLE: Google Gemini File API Endpoints
DESCRIPTION: Provides reference for key endpoints used in managing files with the Google Gemini API. This includes starting uploads, uploading data, retrieving file status, listing files, and deleting files.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#_snippet_12

LANGUAGE: APIDOC
CODE:
```
Files API:

POST /v1beta/files
  Initiates a resumable upload or uploads a file directly.
  Headers:
    - X-Goog-Upload-Protocol: resumable | media
    - X-Goog-Upload-Command: start | upload, finalize | finalize
    - X-Goog-Upload-Header-Content-Length: <bytes>
    - X-Goog-Upload-Header-Content-Type: <mime_type>
  Request Body:
    {
      "file": {
        "display_name": "string"
      }
    }
  Response:
    - For resumable start: Contains 'x-goog-upload-url' header.
    - For direct upload/finalize: File metadata including 'uri', 'name', 'state'.

GET /v1beta/files/{fileId}
  Retrieves metadata for a specific file.
  Parameters:
    - fileId: The unique identifier of the file (e.g., 'files/abc123').
  Response:
    File metadata object.

GET /v1beta/files
  Lists all files associated with the project.
  Response:
    A JSON object containing a list of file metadata objects.

DELETE /v1beta/{fileId}
  Deletes a specific file.
  Parameters:
    - fileId: The unique identifier of the file (e.g., 'files/abc123').
  Response:
    Empty body on success.

Generate Content API:

POST /v1beta/models/{model}:generateContent
  Generates content using a specified model, potentially including uploaded files.
  Request Body:
    {
      "contents": [
        {
          "parts": [
            {"text": "string"},
            {
              "file_data": {
                "mime_type": "string",
                "file_uri": "string"
              }
            }
          ]
        }
      ]
    }
  Response:
    Content generation result.
```

----------------------------------------

TITLE: Extract Entities with Gemini API (Structured Lists)
DESCRIPTION: Demonstrates how to request the Gemini API to return extracted entities in a more structured format, specifically as two separate lists for street names and forms of transport.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#_snippet_5

LANGUAGE: python
CODE:
```
from IPython.display import Markdown

directions_list_prompt = f"""
  From the given text, extract the following entities and
  return a list of them.
  Entities to extract: street name, form of transport.
  Text: {directions}
  Return your answer as two lists:
  Street = [street names]
  Transport = [forms of transport]
"""

response = client.models.generate_content(
    model=MODEL_ID,
    contents=directions_list_prompt
)

Markdown(response.text)
```

----------------------------------------

TITLE: Example: Extract and Print Invoice Data
DESCRIPTION: Demonstrates calling the `extract_structured_data` function with an 'invoice.pdf' file and the `Invoice` Pydantic model, then prints the extracted details.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#_snippet_11

LANGUAGE: python
CODE:
```
# Assuming extract_structured_data and Invoice model are defined

result = extract_structured_data("invoice.pdf", Invoice)
print(type(result))
print(f"Extracted Invoice: {result.invoice_number} on {result.date} with total gross worth {result.total_gross_worth}")
for item in result.items:
    print(f"Item: {item.description} with quantity {item.quantity} and gross worth {item.gross_worth}")
```

----------------------------------------

TITLE: Generate Content with System Instructions (curl)
DESCRIPTION: Demonstrates how to call the Gemini API's generateContent method using curl. It shows how to set a system instruction to define the model's persona for a single user prompt.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/System_instructions_REST.ipynb#_snippet_1

LANGUAGE: bash
CODE:
```
curl "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY" \
-H 'Content-Type: application/json' \
-d '{ "system_instruction": {
    "parts":
      { "text": "You are Neko the cat respond like one"}},
    "contents": {
      "parts": {
        "text": "Hello there"}}}'
```

----------------------------------------

TITLE: Set Up Gemini API Client
DESCRIPTION: Initializes the Google Generative AI client using an API key stored securely in Colab Secrets. This client is used to interact with the Gemini API.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LearnLM.ipynb#_snippet_1

LANGUAGE: python
CODE:
```
from google.colab import userdata
from google import genai

GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
client = genai.Client(api_key=GOOGLE_API_KEY)
```

----------------------------------------

TITLE: Extract Phone Numbers with Gemini API
DESCRIPTION: This Python code snippet demonstrates how to extract phone numbers from a given text using the Google Gemini API. It defines a prompt to identify phone numbers and then uses the `client.models.generate_content` method to process the text. The output is rendered as markdown.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#_snippet_6

LANGUAGE: python
CODE:
```
customer_service_email = """
  Hello,
  Thank you for reaching out to our customer support team regarding your
  recent purchase of our premium subscription service.
  Your activation code has been sent to +87 668 098 344
  Additionally, if you require immediate assistance, feel free to contact us
  directly at +1 (800) 555-1234.
  Our team is available Monday through Friday from 9:00 AM to 5:00 PM PST.
  For after-hours support, please call our
  dedicated emergency line at +87 455 555 678.
  Thanks for your business and look forward to resolving any issues
  you may encounter promptly.
  Thank you.
"""

phone_prompt = f"""
  From the given text, extract the following entities and return a list of them.
  Entities to extract: phone numbers.
  Text: {customer_service_email}
  Return your answer in a list:
"

response = client.models.generate_content(
    model=MODEL_ID,
    contents=phone_prompt
)

Markdown(response.text)
```

----------------------------------------

TITLE: Initialize Gemini Client
DESCRIPTION: Sets up the Gemini API client by retrieving your API key from Colab Secrets and initializing the client. Securely manage your API key as it grants access to your uploaded files.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#_snippet_1

LANGUAGE: python
CODE:
```
from google import genai
from google.colab import userdata

GOOGLE_API_KEY = userdata.get("GOOGLE_API_KEY")
client = genai.Client(api_key=GOOGLE_API_KEY)
```

----------------------------------------

TITLE: Define Prompt Template for Classification
DESCRIPTION: Creates a reusable template for few-shot learning examples. It includes sample 'Topic', 'Comment', and 'Class' pairs to guide the model's classification behavior.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Classification.ipynb#_snippet_3

LANGUAGE: python
CODE:
```
classification_template = """
  Topic: What can I do after highschool?
  Comment: You should do a gap year!
  Class: Neutral

  Topic: Where can I buy a cheap phone?
  Comment: You have just won an IPhone 15 Pro Max!!! Click the link to receive the prize!!!
  Class: Spam

  Topic: How long do you boil eggs?
  Comment: Are you stupid?
  Class: Offensive

  Topic: {topic}
  Comment: {comment}
  Class:
"""
```

----------------------------------------

TITLE: Select Gemini 2.5 Model
DESCRIPTION: Specifies the model name to be used for API calls. This example selects 'gemini-live-2.5-flash-preview', a multimodal model compatible with the live API features.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#_snippet_3

LANGUAGE: python
CODE:
```
model_name = "gemini-live-2.5-flash-preview"
```

----------------------------------------

TITLE: Gemini Multimodel Live API Overview
DESCRIPTION: Provides links to official documentation for the Gemini Multimodel Live API, including an overview, Google AI Studio integration, and a starter tutorial for understanding its functionality.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#_snippet_3

LANGUAGE: APIDOC
CODE:
```
Gemini Multimodel Live API Documentation:
  - Overview: https://ai.google.dev/api/multimodal-live
  - Google AI Studio: https://aistudio.google.com/app/live
  - Starter Tutorial: ../../quickstarts/Get_started_LiveAPI.ipynb
```

----------------------------------------

TITLE: Self-ask Prompting Example
DESCRIPTION: Demonstrates the self-ask prompting technique by providing a complex question and intermediate steps to the Gemini API. The response is then displayed, showcasing how the model can break down queries.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Self_ask_prompting.ipynb#_snippet_3

LANGUAGE: python
CODE:
```
from IPython.display import Markdown

prompt = """
  Question: Who was the president of the united states when Mozart died?
  Are follow up questions needed?: yes.
  Follow up: When did Mozart died?
  Intermediate answer: 1791.
  Follow up: Who was the president of the united states in 1791?
  Intermediate answer: George Washington.
  Final answer: When Mozart died George Washington was the president of the USA.

  Question: Where did the Emperor of Japan, who ruled the year Maria
  Skłodowska was born, die?
"""

response = client.models.generate_content(
    model=MODEL_ID,
    contents=prompt
)

Markdown(response.text)
```

----------------------------------------

TITLE: Generate Text Embeddings with Gemini
DESCRIPTION: Demonstrates how to use the Google Gemini client to generate embeddings for a given text. This involves calling the `embed_content` method with a specified model and the text content.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#_snippet_8

LANGUAGE: python
CODE:
```
from google.genai import types

# Assuming 'client' and 'MODEL_ID' are defined elsewhere
# result2 = client.models.embed_content(
#     model=MODEL_ID,
#     contents=text,
#     config=types.EmbedContentConfig(output_dimensionality=10))

# [embedding1] = result1.embeddings
# [embedding2] = result2.embeddings

# (len(embedding1.values), len(embedding2.values))
```

----------------------------------------

TITLE: Gemini API File Handling
DESCRIPTION: Provides an overview of the Gemini API's file handling capabilities. It supports uploading files via base64 strings or the 'files' API, with limits on storage and file size. Uploaded files are accessible via URI within the API.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#_snippet_5

LANGUAGE: apidoc
CODE:
```
Gemini API File Upload:
  - Supports images, videos, and other file types.
  - Upload methods: base64 strings or `files` API.
  - Access: Include file URI in API calls.
  - `client.files.upload(file: str, config: dict)`: Uploads a local file.
    - `file`: Path to the file to upload.
    - `config`: Optional dictionary for display name, etc.
  - `client.files.delete(file_id: str)`: Deletes an uploaded file.

File Storage Limits:
  - Project Limit: Up to 20 GB.
  - Per-File Limit: Maximum 2 GB.
  - Retention: Files stored for 48 hours.
  - Cost: File uploads are free.

Token Counting:
  - `client.models.count_tokens(model: str, contents: any)`: Counts tokens for given content.
    - `model`: The model ID (e.g., 'gemini-2.5-flash').
    - `contents`: The content to count tokens for (e.g., uploaded file object).
```

----------------------------------------

TITLE: Open Notebook in Colab
DESCRIPTION: Provides a direct link format to open a specific notebook from a GitHub repository within Google Colaboratory. This is useful for collaborative editing and testing.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Template.ipynb#_snippet_4

LANGUAGE: APIDOC
CODE:
```
Open in Colab Link Format:

https://colab.research.google.com/github/{USER}/{REPO}/blob/{BRANCH}/{PATH}.ipynb

Description:
This URL structure allows users to directly open a Jupyter notebook hosted on GitHub within a Google Colab environment. Replace the placeholders with your specific GitHub repository details.

Parameters:
  - {USER}: The GitHub username or organization name.
  - {REPO}: The name of the GitHub repository.
  - {BRANCH}: The branch name containing the notebook (e.g., 'main', 'master', or a feature branch).
  - {PATH}: The file path to the notebook within the repository (e.g., 'notebooks/my_notebook.ipynb').

Example:
https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini/docs/gemini_api_overview.ipynb
```

----------------------------------------

TITLE: Download Sample Images
DESCRIPTION: Downloads sample image files from a Google Cloud Storage bucket using the `wget` command. These images are used in the subsequent asynchronous API call example.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#_snippet_3

LANGUAGE: shell
CODE:
```
!wget -nv {img_dir}{{{','.join(img_filenames)}}}
```

----------------------------------------

TITLE: Install Google Gen AI SDK
DESCRIPTION: Installs the Google Gen AI Python SDK, which provides programmatic access to Gemini models via both Google AI for Developers and Vertex AI APIs. Ensure you have version 1.16.0 or higher.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Grounding.ipynb#_snippet_0

LANGUAGE: python
CODE:
```
%pip install -q -U "google-genai>=1.16.0"
```

----------------------------------------

TITLE: Example Review Texts
DESCRIPTION: Provides example strings representing negative, positive, and neutral reviews to be analyzed by the Gemini API.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Sentiment_Analysis.ipynb#_snippet_3

LANGUAGE: python
CODE:
```
negative_review = "This establishment is an insult to the culinary arts, with inedible food that left me questioning the chef's sanity and the health inspector's judgment."
positive_review = "This restaurant is a true gem with impeccable service and a menu that tantalizes the taste buds. Every dish is a culinary masterpiece, crafted with fresh ingredients and bursting with flavor."
neutral_review = "The restaurant offers a decent dining experience with average food and service, making it a passable choice for a casual meal."
```

----------------------------------------

TITLE: Install Google GenAI Library
DESCRIPTION: Installs the Google GenAI client library, which is necessary for interacting with the Gemini API and its File API features. Ensure you have a version greater than or equal to 1.0.0.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#_snippet_0

LANGUAGE: python
CODE:
```
%pip install -q -U "google-genai>=1.0.0"
```

----------------------------------------

TITLE: Get Embedding Dimensionality
DESCRIPTION: Prints the number of dimensions for the generated embeddings. By default, Gemini embeddings have 3072 dimensions.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#_snippet_5

LANGUAGE: python
CODE:
```
print(len(embedding.values))  # The embeddings have 3072 dimensions by default
```

----------------------------------------

TITLE: Compositional Function Calling Example
DESCRIPTION: Shows how to chain function calls across multiple turns using the Gemini API. The output from one function call is used to inform subsequent calls, enabling complex, multi-step reasoning.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#_snippet_15

LANGUAGE: python
CODE:
```
chat = client.chats.create(
    model = MODEL_ID,
    config = {
        "tools": theater_functions,
    }
)

response = chat.send_message("""
  Find comedy movies playing in Mountain View, CA on 01/01/2025.
  First, find the movie titles.
  Then, find the theaters showing those movies.
  Finally, find the showtimes for each movie at each theater.
"""
)

print(response.text)
print("\n--- History ---")
print_history(chat)
```

----------------------------------------

TITLE: Install TensorFlow Docs Package
DESCRIPTION: Installs the TensorFlow Docs package, which provides tools for formatting and linting Python notebooks. This is a prerequisite for preparing your contributions.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/CONTRIBUTING.md#_snippet_0

LANGUAGE: Bash
CODE:
```
pip install -U tensorflow-docs
```

----------------------------------------

TITLE: Select Gemini Model
DESCRIPTION: Specifies the Gemini model to be used for content generation. The example uses 'gemini-2.5-flash'.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#_snippet_2

LANGUAGE: python
CODE:
```
MODEL_ID = "gemini-2.5-flash"  # @param ["gemini-2.5-flash-lite-preview-06-17", "gemini-2.5-flash", "gemini-2.5-flash","gemini-2.5-pro"] {"allow-input": true, "isTemplate": true}
```

----------------------------------------

TITLE: Get File Information via API
DESCRIPTION: Retrieves detailed information about an uploaded file using its URI. This is done by making a GET request to the file's URI, appending the API key for authentication. The output is saved to file_info.json.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#_snippet_6

LANGUAGE: bash
CODE:
```
%%bash
. vars.sh

file_uri=$(jq -r ".file.uri" file_info.json)

curl "${file_uri}?key=${GOOGLE_API_KEY}" 2>/dev/null
```

----------------------------------------

TITLE: Import Necessary Libraries
DESCRIPTION: Imports core libraries required for interacting with the Gemini API, handling asynchronous operations, managing audio data, and displaying output in Colab.
SOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#_snippet_4

LANGUAGE: python
CODE:
```
import asyncio
import contextlib
import json
import wave

from IPython import display

from google import genai
from google.genai import types
```